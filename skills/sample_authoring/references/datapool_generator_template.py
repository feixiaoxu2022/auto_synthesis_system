"""
æ•°æ®æ± ç”Ÿæˆå™¨æ¨¡æ¿
================

è¾“å‡ºæ ¼å¼ï¼šJSONLï¼ˆæ¯è¡Œä¸€æ¡JSONè®°å½•ï¼‰
è¾“å‡ºä½ç½®ï¼šå·¥ä½œç›®å½•ä¸‹çš„ data_pools/ ç›®å½•

å¤åˆ¶æ­¤æ–‡ä»¶åï¼ŒæŒ‰ä»¥ä¸‹æ­¥éª¤ä¿®æ”¹ï¼š
1. [CONFIG] åŒºï¼šä¿®æ”¹ SYSTEM_TIMEã€OUTPUT_DIRã€ENTITY_COUNTS
2. [DISTRIBUTIONS] åŒºï¼šæ ¹æ® unified_scenario_design.yaml çš„ entities å®šä¹‰åˆ†å¸ƒ
3. [GENERATORS] åŒºï¼šä¸ºæ¯ä¸ªå®ä½“å®ç°ç”Ÿæˆå‡½æ•°
4. [RELATIONS] åŒºï¼šå¤„ç†å®ä½“é—´å¼•ç”¨å…³ç³»

æ³¨æ„ï¼šOUTPUT_DIR åº”æŒ‡å‘å·¥ä½œç›®å½•ä¸‹çš„ data_pools/ ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
"""

import json
import random
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Tuple


# ============================================
# [CONFIG] åŸºç¡€é…ç½® - å¿…é¡»ä¿®æ”¹
# ============================================

# TODO: ä» unified_scenario_design.yaml çš„ runtime_config.system_time è·å–
SYSTEM_TIME = datetime(2024, 1, 1, 9, 0, 0)

# TODO: ä¿®æ”¹ä¸ºå·¥ä½œç›®å½•ä¸‹çš„ data_pools/ è·¯å¾„
# æ–¹å¼1ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰ï¼šOUTPUT_DIR = Path("data_pools")
# æ–¹å¼2ï¼ˆç»å¯¹è·¯å¾„ï¼‰ï¼šOUTPUT_DIR = Path("/absolute/path/to/working_dir/data_pools")
OUTPUT_DIR = Path("data_pools")  # é»˜è®¤ä½¿ç”¨ç›¸å¯¹è·¯å¾„

# TODO: å®šä¹‰å„å®ä½“ç”Ÿæˆæ•°é‡
ENTITY_COUNTS = {
    # "entity_name": count,
}


# ============================================
# [DISTRIBUTIONS] åˆ†å¸ƒé…ç½® - æ ¹æ®ä¸šåŠ¡è§„åˆ™å®šä¹‰
# ============================================

# TODO: ä» YAML çš„ entities.*.attributes.*.distribution æå–
# æšä¸¾å­—æ®µåˆ†å¸ƒ
ENUM_DISTRIBUTIONS = {
    # "field_name": {"value1": 0.5, "value2": 0.3, "value3": 0.2},
}

# æ•°å€¼å­—æ®µåˆ†å±‚ï¼ˆç¡®ä¿è¾¹ç•Œå€¼è¦†ç›–ï¼‰
NUMERIC_TIERS = {
    # "field_name": [
    #     (0.2, (0, 10)),     # 20% åœ¨ 0-10 åŒºé—´
    #     (0.5, (11, 50)),    # 50% åœ¨ 11-50 åŒºé—´
    #     (0.3, (51, 100)),   # 30% åœ¨ 51-100 åŒºé—´
    # ],
}


# ============================================
# [UTILS] å·¥å…·å‡½æ•° - æ— éœ€ä¿®æ”¹
# ============================================

def weighted_choice(distribution: Dict[str, float]) -> str:
    """æŒ‰æƒé‡éšæœºé€‰æ‹©æšä¸¾å€¼"""
    items = list(distribution.keys())
    weights = list(distribution.values())
    return random.choices(items, weights=weights, k=1)[0]


def tiered_random(tiers: List[Tuple[float, Tuple[int, int]]]) -> int:
    """åˆ†å±‚éšæœºæ•°ï¼Œç¡®ä¿å„åŒºé—´è¦†ç›–"""
    tier = random.choices([t[1] for t in tiers], weights=[t[0] for t in tiers], k=1)[0]
    return random.randint(tier[0], tier[1])


def gen_id(prefix: str, index: int, width: int = 3) -> str:
    """ç”Ÿæˆæ ‡å‡†ID: PREFIX_001"""
    return f"{prefix}_{index:0{width}d}"


def random_time_before(base: datetime, max_days: int = 30) -> datetime:
    """åŸºå‡†æ—¶é—´ä¹‹å‰çš„éšæœºæ—¶é—´"""
    return base - timedelta(days=random.randint(1, max_days), hours=random.randint(0, 23))


def random_time_after(base: datetime, max_days: int = 14) -> datetime:
    """åŸºå‡†æ—¶é—´ä¹‹åçš„éšæœºæ—¶é—´"""
    return base + timedelta(days=random.randint(1, max_days), hours=random.randint(9, 18))


# ============================================
# [GENERATORS] å®ä½“ç”Ÿæˆå‡½æ•° - å¿…é¡»å®ç°
# ============================================

def generate_primary_entity(count: int) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆä¸»å®ä½“ï¼ˆå¦‚ employees, users, advertisersï¼‰

    TODO: æ ¹æ® unified_scenario_design.yaml çš„ entities å®šä¹‰å®ç°

    ç¤ºä¾‹ç»“æ„ï¼š
    {
        "entity_id": "ENT_001",
        "name": "...",
        "enum_field": weighted_choice(ENUM_DISTRIBUTIONS["enum_field"]),
        "numeric_field": tiered_random(NUMERIC_TIERS["numeric_field"]),
        "created_at": "2024-01-01 09:00:00"
    }
    """
    entities = []
    for i in range(1, count + 1):
        entity = {
            "id": gen_id("ENT", i),
            # TODO: æ·»åŠ å…¶ä»–å­—æ®µ
        }
        entities.append(entity)
    return entities


def generate_secondary_entity(primary_entities: List[Dict], count: int) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆå…³è”å®ä½“ï¼ˆå¦‚ orders, applications, bookingsï¼‰

    æ³¨æ„ï¼šå¿…é¡»å¼•ç”¨ primary_entities ä¸­çœŸå®å­˜åœ¨çš„ ID

    TODO: å®ç°å…·ä½“ç”Ÿæˆé€»è¾‘
    """
    entities = []
    for i in range(1, count + 1):
        # éšæœºé€‰æ‹©ä¸€ä¸ªä¸»å®ä½“å»ºç«‹å…³è”
        primary = random.choice(primary_entities)

        entity = {
            "id": gen_id("SEC", i),
            "primary_id": primary["id"],  # å¤–é”®å¼•ç”¨
            # TODO: æ·»åŠ å…¶ä»–å­—æ®µ
        }
        entities.append(entity)
    return entities


def generate_with_dependencies(count: int) -> List[Dict[str, Any]]:
    """
    ç”Ÿæˆæœ‰ä¾èµ–å…³ç³»çš„å®ä½“ï¼ˆå¦‚ tasks with dependenciesï¼‰

    ç­–ç•¥ï¼šåˆ†å±‚ç”Ÿæˆ
    1. å…ˆç”Ÿæˆ 70% æ— ä¾èµ–å®ä½“
    2. å†åŸºäºå·²æœ‰å®ä½“ç”Ÿæˆ 30% æœ‰ä¾èµ–å®ä½“
    """
    entities = []

    # Step 1: æ— ä¾èµ–å®ä½“
    independent_count = int(count * 0.7)
    for i in range(independent_count):
        entity = {
            "id": gen_id("DEP", i),
            "dependencies": None,
            "created_time": random_time_before(SYSTEM_TIME),
        }
        entities.append(entity)

    # Step 2: æœ‰ä¾èµ–å®ä½“ï¼ˆå¼•ç”¨å·²å­˜åœ¨çš„å®ä½“ï¼‰
    for i in range(independent_count, count):
        dep_entity = random.choice(entities)
        entity = {
            "id": gen_id("DEP", i),
            "dependencies": [dep_entity["id"]],
            "created_time": dep_entity["created_time"] + timedelta(hours=random.randint(1, 24)),
        }
        entities.append(entity)

    return entities


# ============================================
# [VALIDATION] éªŒè¯å‡½æ•° - æ— éœ€ä¿®æ”¹
# ============================================

def validate_data_pool(data: Dict[str, List]) -> bool:
    """éªŒè¯æ•°æ®æ± å®Œæ•´æ€§"""
    errors = []

    # 1. IDå”¯ä¸€æ€§
    for entity_type, entities in data.items():
        if not entities:
            continue
        id_field = next((k for k in entities[0].keys() if "id" in k.lower()), None)
        if id_field:
            ids = [e.get(id_field) for e in entities]
            if len(ids) != len(set(ids)):
                errors.append(f"{entity_type}: å­˜åœ¨é‡å¤ID")

    # 2. å¤–é”®å¼•ç”¨æœ‰æ•ˆæ€§ï¼ˆéœ€è¦è‡ªå®šä¹‰æ£€æŸ¥é€»è¾‘ï¼‰
    # TODO: æ ¹æ®å®é™…å®ä½“å…³ç³»æ·»åŠ éªŒè¯

    if errors:
        print("âŒ éªŒè¯å¤±è´¥:")
        for err in errors:
            print(f"  - {err}")
        return False

    print("âœ… æ•°æ®æ± éªŒè¯é€šè¿‡")
    return True


def print_stats(data: Dict[str, List]) -> None:
    """æ‰“å°æ•°æ®ç»Ÿè®¡"""
    print("\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    for entity_type, entities in data.items():
        print(f"  {entity_type}: {len(entities)} æ¡")


# ============================================
# [MAIN] ä¸»å‡½æ•° - ä¿®æ”¹å®ä½“ç”Ÿæˆè°ƒç”¨
# ============================================

def main():
    print(f"ğŸš€ ç”Ÿæˆæ•°æ®æ±  (åŸºå‡†æ—¶é—´: {SYSTEM_TIME})")

    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # TODO: æŒ‰ä¾èµ–é¡ºåºè°ƒç”¨ç”Ÿæˆå‡½æ•°
    # 1. å…ˆç”Ÿæˆè¢«å¼•ç”¨å®ä½“
    # primary = generate_primary_entity(ENTITY_COUNTS["primary"])

    # 2. å†ç”Ÿæˆå¼•ç”¨æ–¹å®ä½“
    # secondary = generate_secondary_entity(primary, ENTITY_COUNTS["secondary"])

    # ç»„è£…æ•°æ®æ± 
    data_pool = {
        # "primary": primary,
        # "secondary": secondary,
    }

    # éªŒè¯
    if not validate_data_pool(data_pool):
        return

    print_stats(data_pool)

    # ä¿å­˜ä¸ºJSONLæ ¼å¼
    for name, entities in data_pool.items():
        path = OUTPUT_DIR / f"{name}.jsonl"
        with open(path, 'w', encoding='utf-8') as f:
            for entity in entities:
                f.write(json.dumps(entity, ensure_ascii=False) + '\n')
        print(f"âœ… ä¿å­˜ {path}")


if __name__ == "__main__":
    main()
